{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection\n",
    "\n",
    "Cette fonctionnalité permet de détecter des visages humains sur une image et d'en extraire certaines caractéristiques comme la localisation sur l'image, l'âge prédit, l'émotion..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from json import dump\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import cv2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement de la clé d'API et du endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "cog_endpoint = os.getenv(\"COG_SERVICE_ENDPOINT\")\n",
    "cog_key = os.getenv(\"COG_SERVICE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prise de photo avec la webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = cv2. waitKey(1)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    try:\n",
    "        check, frame = webcam.read()\n",
    "        print(check) #prints true as long as the webcam is running\n",
    "        print(frame) #prints matrix values of each framecd \n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('s'): \n",
    "            cv2.imwrite(filename='saved_img.jpg', img=frame)\n",
    "            webcam.release()\n",
    "            img_new = cv2.imread('saved_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "            img_new = cv2.imshow(\"Captured Image\", img_new)\n",
    "            cv2.waitKey(1650)\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Processing image...\")\n",
    "            img_ = cv2.imread('saved_img.jpg', cv2.IMREAD_ANYCOLOR)\n",
    "            \n",
    "            print(\"Image saved!\")\n",
    "        \n",
    "            break\n",
    "        elif key == ord('q'):\n",
    "            print(\"Turning off camera.\")\n",
    "            webcam.release()\n",
    "            print(\"Camera off.\")\n",
    "            print(\"Program ended.\")\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "    except(KeyboardInterrupt):\n",
    "        print(\"Turning off camera.\")\n",
    "        webcam.release()\n",
    "        print(\"Camera off.\")\n",
    "        print(\"Program ended.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilisation du module Detect de Face API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif : détecter le ou les visage(s) présent(s) dans l'image et extraire pour chaque visage l'âge, le genre et l'émotion correspondants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(key, endpoint, img):\n",
    "    # construct the API URL endpoint for the Language Detection service (use `cog_endpoint`)\n",
    "    url = f\"{endpoint}face/v1.0/detect\"\n",
    "    \n",
    "    # fill the required headers to authenticate with the API (use `cog_key`)\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/octet-stream\",\n",
    "        \"Ocp-Apim-Subscription-Key\": key,\n",
    "    }\n",
    "\n",
    "    with open(img,'rb') as image:\n",
    "        \n",
    "        # fill the request body parameters with the input text\n",
    "        '''\n",
    "        body = {\n",
    "            \"url\": img\n",
    "        }\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        params = {\n",
    "            \"returnFaceAttributes\": \"age,gender,emotion\",\n",
    "            \"recognitionModel\": \"recognition_04\",\n",
    "        }\n",
    "\n",
    "        # make a POST request to the API using the url, the headers and the JSON body parameters\n",
    "        response = requests.post(url, data=image, params=params, headers=headers)\n",
    "\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        \n",
    "        # On récupère les attributs âge, genre, émotion ainsi que les coordonnées de la position pour chaque visage détecté\n",
    "        face_att = []\n",
    "        \n",
    "        for face in data:\n",
    "            rect = {}\n",
    "            age = face['faceAttributes']['age']\n",
    "            gender = face['faceAttributes']['gender']\n",
    "            emotion = max(face['faceAttributes']['emotion'], key=face['faceAttributes']['emotion'].get)\n",
    "            score_emotion = max(face['faceAttributes']['emotion'].values())\n",
    "            rect['top'] = face['faceRectangle'][\"top\"]\n",
    "            rect['left'] = face['faceRectangle'][\"left\"]\n",
    "            rect['width'] = face['faceRectangle'][\"width\"]\n",
    "            rect['height'] = face['faceRectangle'][\"height\"]\n",
    "            face_att.append((age,gender,emotion,rect))\n",
    "        \n",
    "        # Afficher l'image avec le rectangle détectant les visages avec les annotations\n",
    "        \n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "        plt.axis('off')\n",
    "        image = Image.open(img)\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        color = 'red'\n",
    "\n",
    "        for face in face_att:\n",
    "\n",
    "                # Get face properties\n",
    "                    \n",
    "                print(' - Age: {}'.format(face[0]))\n",
    "                            \n",
    "                print(' - Emotion: {}'.format(face[2]))\n",
    "                        \n",
    "                print(' - Gender:{}'.format(face[1]))\n",
    "                        \n",
    "                print()\n",
    "\n",
    "                # Draw and annotate face\n",
    "                age = face[0]\n",
    "                gender = face[1]\n",
    "                emotion = face[2]\n",
    "                left = face[3]['left']\n",
    "                top = face[3]['top']\n",
    "                width = face[3]['width']\n",
    "                height = face[3]['height']\n",
    "                bounding_box = ((left,top), (left + width, top + height))\n",
    "                draw = ImageDraw.Draw(image)\n",
    "                        \n",
    "                if gender == 'female':\n",
    "                    draw.rectangle(bounding_box, outline='green', width=4)\n",
    "                else:\n",
    "                    draw.rectangle(bounding_box, outline='red', width=4)\n",
    "                            \n",
    "                annotation = age\n",
    "                        \n",
    "                if gender == 'female':\n",
    "                    plt.annotate(annotation,(left, top), backgroundcolor='green')\n",
    "                    plt.annotate(f\"{emotion} : {score_emotion}\",(left+width/4, top+height*1.1), backgroundcolor='green')\n",
    "                else:\n",
    "                    plt.annotate(annotation,(left, top), backgroundcolor='red')\n",
    "                    plt.annotate(f\"{emotion} : {score_emotion}\",(left+width/4, top+height*1.2), backgroundcolor='red')\n",
    "\n",
    "        # Save annotated image\n",
    "        plt.imshow(image)\n",
    "        outputfile = 'detected_faces.jpg'\n",
    "        fig.savefig(outputfile)\n",
    "\n",
    "        print('\\nResults saved in', outputfile)\n",
    "\n",
    "        return face_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = detect_face(cog_key, cog_endpoint, 'surprise.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9f0e8019c403664c3648e0839e9aaf166627bf278a81999a17fa18bfc8e77e3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('projet-3-groupe-2-SbrQwao8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
