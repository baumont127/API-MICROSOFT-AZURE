{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798d7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from array import array\n",
    "import os\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "#import matplotlib.pypnormal_day.jpglot as plt\n",
    "import cv2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7adc23e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "cog_endpoint = os.getenv(\"COG_SERVICE_ENDPOINT\")\n",
    "cog_key = os.getenv(\"COG_SERVICE_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5886a85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning off camera.\n",
      "Camera off.\n",
      "Program ended.\n"
     ]
    }
   ],
   "source": [
    "key = cv2. waitKey(1)\n",
    "webcam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    try:\n",
    "        check, frame = webcam.read()\n",
    "        \n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('s'): \n",
    "            cv2.imwrite(filename='saved_img.jpg', img=frame)\n",
    "            webcam.release()\n",
    "            img_new = cv2.imread('saved_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "            img_new = cv2.imshow(\"Captured Image\", img_new)\n",
    "            cv2.waitKey(1650)\n",
    "            cv2.destroyAllWindows()\n",
    "            print(\"Processing image...\")\n",
    "            img_ = cv2.imread('saved_img.jpg', cv2.IMREAD_ANYCOLOR)\n",
    "            \n",
    "            print(\"Image saved!\")\n",
    "        \n",
    "            break\n",
    "        elif key == ord('q'):\n",
    "            print(\"Turning off camera.\")\n",
    "            webcam.release()\n",
    "            print(\"Camera off.\")\n",
    "            print(\"Program ended.\")\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "        \n",
    "    except(KeyboardInterrupt):\n",
    "        print(\"Turning off camera.\")\n",
    "        webcam.release()\n",
    "        print(\"Camera off.\")\n",
    "        print(\"Program ended.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc897ed9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m results \u001b[38;5;241m=\u001b[39m image_anal\u001b[38;5;241m.\u001b[39mdetect_objects_results_remote\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m\"\"\"if len(results.objects) == 0:\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    print(\"No objects detected.\")\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03melse:\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    for object in results.objects:\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m        print(object)\"\"\"\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m fig \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     44\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     45\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_img.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "def image_anal(img):\n",
    "    # create the Azure Key Credential object with the secret key (use `cog_key`)\n",
    "    #ta_credential = AzureKeyCredential(cog_key)\n",
    "\n",
    "    with open(img,'rb') as image:\n",
    "        \n",
    "        # fill the request body parameters with the input text\n",
    "        '''\n",
    "        body = {\n",
    "            \"url\": img\n",
    "        }\n",
    "        \n",
    "        '''\n",
    "\n",
    "        # create the Azure Text Analytics Client object with the endpoint (use `cog_endpoint`) and the credential object\n",
    "        client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "        \n",
    "        # call the language detection method with the list of documents\n",
    "        #image_anal.description_results = client.describe_image_in_stream(image)\n",
    "        \n",
    "        image_anal.detect_objects_results_remote = client.detect_objects_in_stream(image)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def main_sdk():\n",
    "    image_anal('saved_img.jpg')\n",
    "\n",
    "\n",
    "main_sdk()\n",
    "\n",
    "results = image_anal.detect_objects_results_remote\n",
    "        \n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.axis('off')\n",
    "image = Image.open(\"saved_img.jpg\")\n",
    "draw = ImageDraw.Draw(image)\n",
    "color = 'red'\n",
    "\n",
    "for object in results.objects:\n",
    "\n",
    "        \n",
    "        # Draw and annotate face\n",
    "        name = object.object_property\n",
    "        x = object.rectangle.x\n",
    "        y = object.rectangle.y\n",
    "        w = object.rectangle.w\n",
    "        h = object.rectangle.h\n",
    "        \n",
    "        \n",
    "        bounding_box = ((x,y), (x + w, y + h))\n",
    "\n",
    "        \n",
    "        draw.rectangle(bounding_box, outline='green', width=4)\n",
    "        \n",
    "\n",
    "        annotation = name\n",
    "\n",
    "     \n",
    "        plt.annotate(annotation,(x, y), backgroundcolor='green')\n",
    "        \n",
    "# Save annotated image\n",
    "plt.imshow(image)\n",
    "outputfile = 'saved_img.jpg'\n",
    "fig.savefig(outputfile)\n",
    "\n",
    "#print('\\nResults saved in', outputfile)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af76bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
